#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Tashiro Categorization Adapter
Integrates the Tashiro expense categorization engine with the existing pipeline
"""

from typing import Dict, Any, List, Optional
import logging
import json

from app.categorization.expense_engine import (
    ExpenseCategorizationEngine, 
    CategoryMatch, 
    ExpenseCategory,
    TaxClassification
)

logger = logging.getLogger(__name__)

class TashiroCategorizer:
    """
    Adapter to integrate Tashiro expense categorization into the receipt pipeline
    """
    
    def __init__(self):
        self.engine = ExpenseCategorizationEngine()
    
    def categorize_receipt(self, raw_text: str, vendor: Optional[str] = None, 
                          total_amount: Optional[float] = None) -> Dict[str, Any]:
        """
        Categorize a receipt and return structured results
        
        Args:
            raw_text: Full OCR text from receipt
            vendor: Detected vendor name
            total_amount: Receipt total amount
            
        Returns:
            Dictionary with categorization results
        """
        try:
            # Get categorization matches
            matches = self.engine.categorize_receipt(
                ocr_text=raw_text,
                vendor_name=vendor or "",
                amount=total_amount or 0.0
            )
            
            if not matches:
                # Default to "Other" category if no matches found
                matches = [CategoryMatch(
                    category=ExpenseCategory.OTHER,
                    confidence=0.3,
                    matched_keywords=["æœªåˆ†é¡"],
                    tax_classification=TaxClassification.UNKNOWN
                )]
            
            primary_match = matches[0]
            
            # Get display information for primary category
            display_info = self.engine.get_category_display_info(primary_match.category)
            
            # Format categorization result
            result = {
                "primary_category": {
                    "category": primary_match.category.value,
                    "category_english": primary_match.category.name.title(),
                    "confidence": primary_match.confidence,
                    "color": display_info["color"],
                    "icon": display_info["icon"],
                    "tax_classification": primary_match.tax_classification.value,
                    "matched_keywords": primary_match.matched_keywords
                },
                "all_categories": [
                    {
                        "category": match.category.value,
                        "category_english": match.category.name.title(),
                        "confidence": match.confidence,
                        "color": self.engine.get_category_display_info(match.category)["color"],
                        "icon": self.engine.get_category_display_info(match.category)["icon"],
                        "tax_classification": match.tax_classification.value,
                        "matched_keywords": match.matched_keywords
                    }
                    for match in matches[:3]  # Top 3 matches
                ],
                "categorization_summary": {
                    "total_matches": len(matches),
                    "high_confidence_matches": len([m for m in matches if m.confidence > 0.7]),
                    "has_tax_info": any(m.tax_classification != TaxClassification.UNKNOWN for m in matches),
                    "vendor_matched": vendor is not None and len(vendor.strip()) > 0
                },
                "tashiro_workflow_data": {
                    "business_unit": self._determine_business_unit(raw_text, vendor),
                    "approval_level": self._determine_approval_level(total_amount or 0),
                    "journal_entry_code": self._get_journal_entry_code(primary_match.category),
                    "requires_receipt_attachment": True,
                    "processing_notes": self._generate_processing_notes(matches, raw_text)
                }
            }
            
            logger.info(f"Categorized receipt: {primary_match.category.value} "
                       f"({primary_match.confidence:.1%} confidence)")
            
            return result
            
        except Exception as e:
            logger.exception(f"Error categorizing receipt: {e}")
            
            # Return default categorization on error
            return {
                "primary_category": {
                    "category": "ãã®ä»–",
                    "category_english": "Other",
                    "confidence": 0.1,
                    "color": "#95A5A6",
                    "icon": "ğŸ“‹",
                    "tax_classification": "ç¨åŒºåˆ†ä¸æ˜",
                    "matched_keywords": ["ã‚¨ãƒ©ãƒ¼"]
                },
                "all_categories": [],
                "categorization_summary": {
                    "total_matches": 0,
                    "high_confidence_matches": 0,
                    "has_tax_info": False,
                    "vendor_matched": False
                },
                "tashiro_workflow_data": {
                    "business_unit": "æœªå‰²ã‚Šå½“ã¦",
                    "approval_level": "è¦ç¢ºèª",
                    "journal_entry_code": "999",
                    "requires_receipt_attachment": True,
                    "processing_notes": "è‡ªå‹•åˆ†é¡ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚æ‰‹å‹•ã§ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
                }
            }
    
    def _determine_business_unit(self, text: str, vendor: Optional[str]) -> str:
        """Determine business unit based on text content"""
        
        # Business unit keywords based on Tashiro workflow
        unit_keywords = {
            "æœ¬ç¤¾": ["æœ¬ç¤¾", "æ±äº¬", "HQ", "headquarters"],
            "å–¶æ¥­éƒ¨": ["å–¶æ¥­", "sales", "å•†è«‡", "ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"],
            "è£½é€ éƒ¨": ["è£½é€ ", "å·¥å ´", "production", "ææ–™"],
            "æŠ€è¡“éƒ¨": ["æŠ€è¡“", "é–‹ç™º", "R&D", "research"],
            "ç®¡ç†éƒ¨": ["ç®¡ç†", "admin", "äººäº‹", "ç·å‹™"]
        }
        
        text_lower = text.lower()
        
        for unit, keywords in unit_keywords.items():
            if any(keyword.lower() in text_lower for keyword in keywords):
                return unit
        
        return "ä¸€èˆ¬"  # Default unit
    
    def _determine_approval_level(self, amount: float) -> str:
        """Determine required approval level based on amount"""
        
        if amount >= 100000:  # 100,000 yen or more
            return "å–ç· å½¹æ‰¿èª"  # Director approval
        elif amount >= 50000:  # 50,000 yen or more
            return "éƒ¨é•·æ‰¿èª"    # Department manager approval
        elif amount >= 10000:  # 10,000 yen or more
            return "èª²é•·æ‰¿èª"    # Section manager approval
        else:
            return "æ‹…å½“è€…å‡¦ç†"  # Staff processing
    
    def _get_journal_entry_code(self, category: ExpenseCategory) -> str:
        """Get journal entry code for accounting system"""
        
        # Journal entry codes based on Tashiro accounting system
        codes = {
            ExpenseCategory.MEALS: "611",          # é£Ÿè²»
            ExpenseCategory.TRANSPORT: "612",      # äº¤é€šè²»
            ExpenseCategory.COMMUNICATION: "613",  # é€šä¿¡è²»
            ExpenseCategory.ACCOMMODATION: "614",  # å®¿æ³Šè²»
            ExpenseCategory.ENTERTAINMENT: "615",  # æ¥å¾…è²»
            ExpenseCategory.SUPPLIES: "616",       # æ¶ˆè€—å“è²»
            ExpenseCategory.UTILITIES: "617",      # æ°´é“å…‰ç†±è²»
            ExpenseCategory.RENT: "618",           # åœ°ä»£å®¶è³ƒ
            ExpenseCategory.TAXES: "619",          # ç§Ÿç¨å…¬èª²
            ExpenseCategory.TRAVEL: "620",         # æ—…è²»
            ExpenseCategory.EQUIPMENT: "621",      # å‚™å“è²»
            ExpenseCategory.MAINTENANCE: "622",    # ä¿®ç¹•è²»
            ExpenseCategory.FUEL: "623",           # ç‡ƒæ–™è²»
            ExpenseCategory.INSURANCE: "624",      # ä¿é™ºæ–™
            ExpenseCategory.EDUCATION: "625",      # ç ”ä¿®è²»
            ExpenseCategory.OTHER: "699"           # ãã®ä»–
        }
        
        return codes.get(category, "699")
    
    def _generate_processing_notes(self, matches: List[CategoryMatch], raw_text: str) -> str:
        """Generate processing notes for the receipt"""
        
        notes = []
        
        if not matches:
            notes.append("è‡ªå‹•åˆ†é¡ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        elif matches[0].confidence < 0.5:
            notes.append("åˆ†é¡ã®ä¿¡é ¼åº¦ãŒä½ã„ãŸã‚ã€ç¢ºèªãŒå¿…è¦ã§ã™ã€‚")
        
        # Check for mixed categories
        if len(matches) > 1 and matches[1].confidence > 0.4:
            notes.append(f"è¤‡æ•°ã‚«ãƒ†ã‚´ãƒªã®å¯èƒ½æ€§: {matches[1].category.value}")
        
        # Check for special conditions
        if "ãƒ¬ã‚·ãƒ¼ãƒˆ" not in raw_text and "é ˜åæ›¸" not in raw_text:
            notes.append("æ­£å¼ãªé ˜åæ›¸ã§ã¯ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        
        # Tax information notes
        tax_matches = [m for m in matches if m.tax_classification != TaxClassification.UNKNOWN]
        if not tax_matches:
            notes.append("ç¨åŒºåˆ†æƒ…å ±ãŒä¸æ˜ã§ã™ã€‚")
        
        return " ".join(notes) if notes else "æ­£å¸¸ã«å‡¦ç†ã•ã‚Œã¾ã—ãŸã€‚"

# Integration function for existing pipeline
def add_tashiro_categorization(result_dict: Dict[str, Any], raw_text: str, 
                              vendor: Optional[str] = None, 
                              total_amount: Optional[float] = None) -> Dict[str, Any]:
    """
    Add Tashiro categorization to existing extraction result
    
    Args:
        result_dict: Existing extraction result dictionary
        raw_text: Full OCR text
        vendor: Detected vendor name
        total_amount: Receipt total amount
        
    Returns:
        Enhanced result dictionary with categorization
    """
    try:
        categorizer = TashiroCategorizer()
        categorization = categorizer.categorize_receipt(raw_text, vendor, total_amount)
        
        # Add categorization to result
        result_dict.update({
            "tashiro_categorization": categorization,
            "expense_category": categorization["primary_category"]["category"],
            "expense_confidence": categorization["primary_category"]["confidence"],
            "tax_classification": categorization["primary_category"]["tax_classification"],
            "business_unit": categorization["tashiro_workflow_data"]["business_unit"],
            "approval_level": categorization["tashiro_workflow_data"]["approval_level"]
        })
        
        return result_dict
        
    except Exception as e:
        logger.exception(f"Failed to add Tashiro categorization: {e}")
        return result_dict


def normalize_result(engine: str, result: dict) -> dict:
    """
    Normalize different OCR engine outputs into a common schema:
    {
      "engine": "<engine>",
      "status": "ok"|"error",
      "text": "<full_text>",
      "regions": [{"text": "...", "box":[x1,y1,x2,y2], "confidence": 0.9}, ...],
      "meta": {...}
    }
    """
    if not isinstance(result, dict):
        return {"engine": engine, "status": "error", "text": "", "regions": [], "meta": {"raw": result}}

    try:
        if engine == "google_vision":
            # accept either our structured object or raw Vision response
            text = result.get("text") or result.get("full_text_annotation", {}).get("text", "") or ""
            regions = result.get("regions") or []
            return {"engine": "google_vision", "status": "ok", "text": text, "regions": regions, "meta": result.get("meta", {})}
        if engine == "openai":
            text = result.get("text") or ""
            regions = []
            return {"engine": "openai", "status": "ok", "text": text, "regions": regions, "meta": result.get("meta", {})}
        if engine == "ocr_space":
            parsed = result.get("ParsedResults")
            text = ""
            regions = []
            if parsed and len(parsed) > 0:
                text = parsed[0].get("ParsedText", "")
                # Some OCR.space returns word-level; keep meta
            return {"engine": "ocr_space", "status": "ok", "text": text, "regions": regions, "meta": result}
    except Exception as e:
        return {"engine": engine, "status": "error", "text": "", "regions": [], "meta": {"error": str(e), "raw": result}}
    return {"engine": engine, "status": "unknown", "text": json.dumps(result, ensure_ascii=False), "regions": [], "meta": {}}