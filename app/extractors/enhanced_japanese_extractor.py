#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Enhanced Japanese Receipt Field Extractor
Optimized for Japanese receipts with advanced OCR preprocessing, field-specific regex,
and AI-powered post-processing for maximum accuracy.
"""

import os
import re
import json
import unicodedata
from typing import Dict, Any, Optional, List, Tuple
from datetime import datetime
from rapidfuzz import fuzz
import logging

# Import existing extractors for fallback
try:
    from .field_extractors import FieldExtractor
    FIELD_EXTRACTOR_AVAILABLE = True
except ImportError:
    FIELD_EXTRACTOR_AVAILABLE = False

logger = logging.getLogger(__name__)


class EnhancedJapaneseExtractor:
    """
    Enhanced field extractor optimized for Japanese receipts.
    Uses structured OCR data with advanced post-processing.
    """

    def __init__(self):
        """Initialize the enhanced Japanese extractor."""
        self.vendor_database = self._load_vendor_database()
        self.field_patterns = self._initialize_field_patterns()

    def _load_vendor_database(self) -> Dict[str, str]:
        """Load vendor name database for fuzzy matching and categorization."""
        # Comprehensive Japanese vendor database
        vendor_db = {
            # Convenience Stores
            "„É≠„Éº„ÇΩ„É≥": "convenience_store",
            "„É≠„Éº„ÇΩ„É≥„Çπ„Éà„Ç¢": "convenience_store",
            "„Éï„Ç°„Éü„É™„Éº„Éû„Éº„Éà": "convenience_store",
            "„Éï„Ç°„Éü„Éû": "convenience_store",
            "„Çª„Éñ„É≥„Ç§„É¨„Éñ„É≥": "convenience_store",
            "„Çª„Éñ„É≥-„Ç§„É¨„Éñ„É≥": "convenience_store",
            "„Éü„Éã„Çπ„Éà„ÉÉ„Éó": "convenience_store",
            "„Éá„Ç§„É™„Éº„É§„Éû„Ç∂„Ç≠": "convenience_store",
            "„É§„Éû„Ç∂„Ç≠": "convenience_store",
            "„Éã„É•„Éº„Éá„Ç§„Ç∫": "convenience_store",
            "„Éù„Éó„É©": "convenience_store",

            # Restaurants & Food
            "„Éû„ÇØ„Éâ„Éä„É´„Éâ": "restaurant",
            "„Éû„ÉÉ„ÇØ": "restaurant",
            "„É¢„Çπ„Éê„Éº„Ç¨„Éº": "restaurant",
            "„É¢„Çπ": "restaurant",
            "„Ç±„É≥„Çø„ÉÉ„Ç≠„Éº": "restaurant",
            "KFC": "restaurant",
            "„Éî„Ç∂„Éè„ÉÉ„Éà": "restaurant",
            "„Éî„Ç∂": "restaurant",
            "„Éâ„Éü„Éé„Éî„Ç∂": "restaurant",
            "„Åô„ÅçÂÆ∂": "restaurant",
            "ÂêâÈáéÂÆ∂": "restaurant",
            "ÊùæÂ±ã": "restaurant",
            "„Åã„Å§„ÇÑ": "restaurant",
            "Â§ßÊà∏Â±ã": "restaurant",
            "„Åè„ÇâÂØøÂè∏": "restaurant",
            "„Çπ„Ç∑„É≠„Éº": "restaurant",
            "„ÅØ„ÅæÂØøÂè∏": "restaurant",
            "„Åè„Çâ": "restaurant",
            "„Åô„Åó": "restaurant",

            # Supermarkets
            "„Ç§„Ç™„É≥": "supermarket",
            "„Ç§„Ç™„É≥„É¢„Éº„É´": "supermarket",
            "„Ç§„Éà„Éº„É®„Éº„Ç´„Éâ„Éº": "supermarket",
            "„Ç§„Éà„Éº„É®„Éº„Ç´Â†Ç": "supermarket",
            "Ë•øÂèã": "supermarket",
            "Ë•øÂèã„Çπ„Éà„Ç¢": "supermarket",
            "„É©„Ç§„Éï": "supermarket",
            "„É©„Ç§„Éï„Ç≥„Éº„Éù„É¨„Éº„Ç∑„Éß„É≥": "supermarket",
            "„Éû„É´„Ç®„ÉÑ": "supermarket",
            "„Ç™„Éº„Ç±„Éº": "supermarket",
            "„Éô„É´„ÇØ": "supermarket",
            "„É§„Ç™„Ç≥„Éº": "supermarket",
            "„Ç≥„Éº„Éó": "supermarket",
            "ÁîüÂçî": "supermarket",

            # Drug Stores
            "„Éû„ÉÑ„É¢„Éà„Ç≠„É®„Ç∑": "drugstore",
            "„Éû„ÉÑ„Ç≠„É®": "drugstore",
            "„ÉÑ„É´„Éè„Éâ„É©„ÉÉ„Ç∞": "drugstore",
            "„ÉÑ„É´„Éè": "drugstore",
            "„Çπ„ÇÆËñ¨Â±Ä": "drugstore",
            "„Çπ„ÇÆ": "drugstore",
            "„Ç¶„Ç®„É´„Ç∑„Ç¢": "drugstore",
            "„Ç¶„Ç®„É´„Ç∑„Ç¢Ëñ¨Â±Ä": "drugstore",
            "„Ç≥„Ç≥„Ç´„É©„Éï„Ç°„Ç§„É≥": "drugstore",
            "„Ç≥„Ç≥„Ç´„É©": "drugstore",
            "„Çµ„É≥„Éâ„É©„ÉÉ„Ç∞": "drugstore",
            "„Çµ„É≥„Éâ„É©„ÉÉ„Ç∞": "drugstore",

            # Department Stores
            "È´òÂ≥∂Â±ã": "department_store",
            "‰∏âË∂ä": "department_store",
            "‰ºäÂã¢‰∏π": "department_store",
            "ÊùæÂ±ã": "department_store",
            "Êù±ÊÄ•ÁôæË≤®Â∫ó": "department_store",
            "Èò™ÊÄ•ÁôæË≤®Â∫ó": "department_store",
            "Â§ß‰∏∏": "department_store",

            # Other Common Categories
            "„Çπ„Çø„Éº„Éê„ÉÉ„ÇØ„Çπ": "cafe",
            "„Éâ„Éà„Éº„É´": "cafe",
            "„Çø„É™„Éº„Ç∫": "cafe",
            "„Ç≥„É°„ÉÄ": "cafe",
            "„Ç´„Éï„Çß": "cafe",
            "ÈÉµ‰æøÂ±Ä": "post_office",
            "Êó•Êú¨ÈÉµ‰æø": "post_office",
            "ÈäÄË°å": "bank",
            "ATM": "bank",
            "„Ç¨„ÇΩ„É™„É≥„Çπ„Çø„É≥„Éâ": "gas_station",
            "ENEOS": "gas_station",
            "Âá∫ÂÖâ": "gas_station",
            "„Ç≥„Çπ„É¢": "gas_station",
            "Ëñ¨Â±Ä": "pharmacy",
            "ÂåªÈô¢": "medical",
            "„ÇØ„É™„Éº„Éã„É≥„Ç∞": "cleaning",
            "ÁêÜÂÆπÂÆ§": "barber",
            "ÁæéÂÆπÈô¢": "beauty_salon"
        }

        return vendor_db

    def _initialize_field_patterns(self) -> Dict[str, List[str]]:
        """Initialize comprehensive field-specific regex patterns for Japanese receipts."""
        return {
            'date': [
                r'(\d{4}[Âπ¥/-]\d{1,2}[Êúà/-]\d{1,2}Êó•?)',  # 2025Âπ¥7Êúà2Êó•, 2025/7/2, 2025-7-2
                r'(\d{4}Âπ¥\s*\d{1,2}Êúà\s*\d{1,2}Êó•?)',     # 2025Âπ¥ 7Êúà 2Êó•
                r'(\d{1,2}[/-]\d{1,2}[/-]\d{4})',         # 7/2/2025, 07-02-2025
                r'(\d{4}\.\d{1,2}\.\d{1,2})',             # 2025.7.2
                r'(\d{2})[/-](\d{1,2})[/-](\d{1,2})',     # 25-7-2 (assume 20xx)
            ],
            'invoice_number': [
                r'(T-?\d{8,15})',                                   # Japanese invoice/ÁôªÈå≤Áï™Âè∑ starting with T and long digits
                r'(?:No\.?|Áï™Âè∑|‰ºùÁ•®|„É¨„Ç∑„Éº„Éà)\s*[:\s]*([A-Za-z0-9\-]+)',  # No.: 123, Áï™Âè∑: ABC123
                r'([A-Za-z]-?\d{3,14})',                                 # T001234, R123456, T-12345678901234
                r'(\d{4,12})',                                          # Pure numeric: 12345678
            ],
            'subtotal': [
                r'(?:Â∞èË®à|Â∞è\s*Ë®à)\s*[:\s]*[¬•\\]?([0-9,]+\.?[0-9]*)',  # Â∞èË®à: 2848, Â∞è Ë®à ¬•2848
                r'[¬•\\]?([0-9,]+\.?[0-9]*)\s*(?:Â∞èË®à|Â∞è\s*Ë®à)',        # ¬•2848 Â∞èË®à
            ],
            'tax': [
                r'(?:Ê∂àË≤ªÁ®é|ÂÜÖÊ∂àË≤ªÁ®é|Á®é)\s*[:\s]*[¬•\\]?([0-9,]+\.?[0-9]*)',  # Ê∂àË≤ªÁ®é: 258, Á®é ¬•258
                r'[¬•\\]?([0-9,]+\.?[0-9]*)\s*(?:Ê∂àË≤ªÁ®é|ÂÜÖÊ∂àË≤ªÁ®é|Á®é)',        # ¬•258 Ê∂àË≤ªÁ®é
                r'\(\s*(?:Ê∂àË≤ªÁ®é|ÂÜÖÊ∂àË≤ªÁ®é|Á®é)\s*[¬•\\]?([0-9,]+\.?[0-9]*)\s*\)',  # (Ê∂àË≤ªÁ®é ¬•258)
            ],
            'total': [
                r'(?:ÂêàË®à|Á∑èÈ°ç|„ÅäË≤∑‰∏äË®à|Âêà\s*Ë®à)\s*[:\s]*[¬•\\]?([0-9,]+\.?[0-9]*)',  # ÂêàË®à: 3106, Âêà Ë®à ¬•3106
                r'[¬•\\]?([0-9,]+\.?[0-9]*)\s*(?:ÂêàË®à|Á∑èÈ°ç|„ÅäË≤∑‰∏äË®à|Âêà\s*Ë®à)',        # ¬•3106 ÂêàË®à
            ],
            'payment': [
                r'(?:ÁèæÈáë|„ÅäÈ†ê„Çä|È†ê„ÇäÈáë|ÊîØÊâï„ÅÑ)\s*[:\s]*[¬•\\]?([0-9,]+\.?[0-9]*)',  # ÁèæÈáë: 5000, „ÅäÈ†ê„Çä ¬•5000
                r'[¬•\\]?([0-9,]+\.?[0-9]*)\s*(?:ÁèæÈáë|„ÅäÈ†ê„Çä|È†ê„ÇäÈáë|ÊîØÊâï„ÅÑ)',        # ¬•5000 ÁèæÈáë
            ],
            'change': [
                r'(?:„ÅäÈá£„Çä|Èá£Èä≠|„Åä„Å§„Çä)\s*[:\s]*[¬•\\]?([0-9,]+\.?[0-9]*)',  # „ÅäÈá£„Çä: 1894, Èá£Èä≠ ¬•1894
                r'[¬•\\]?([0-9,]+\.?[0-9]*)\s*(?:„ÅäÈá£„Çä|Èá£Èä≠|„Åä„Å§„Çä)',        # ¬•1894 „ÅäÈá£„Çä
            ]
        }

    def extract_fields_enhanced(self, ocr_result: Dict[str, Any], filename: str = "receipt.jpg") -> Dict[str, Any]:
        """
        Extract fields from enhanced OCR result with Japanese-specific processing.

        Args:
            ocr_result: OCR result from Google Vision DOCUMENT_TEXT_DETECTION
            filename: Original filename

        Returns:
            Structured field extraction results
        """
        try:
            print(f"üéØ Enhanced Japanese field extraction for: {filename}")

            # Extract raw text and structured blocks
            raw_text = ""
            text_blocks = []

            if ocr_result.get('ParsedResults') and ocr_result['ParsedResults']:
                raw_text = ocr_result['ParsedResults'][0].get('ParsedText', '')
                text_blocks = ocr_result.get('metadata', {}).get('text_blocks', [])

            if not raw_text and text_blocks:
                # Reconstruct text from blocks if needed
                raw_text = '\n'.join([block.get('text', '') for block in text_blocks])

            # Normalize Japanese text
            normalized_text = self._normalize_japanese_text(raw_text)

            # Extract fields using position-aware processing
            extracted_fields = self._extract_fields_by_position(text_blocks, normalized_text)

            # Apply post-processing logic
            processed_fields = self._apply_post_processing_logic(extracted_fields)

            # Categorize vendor and expense
            category_result = self._categorize_expense_enhanced(processed_fields, normalized_text)

            # Calculate confidence scores
            confidence_scores = self._calculate_field_confidence(processed_fields)

            # Prepare final result
            result = {
                'date': processed_fields.get('date', ''),
                'vendor': processed_fields.get('vendor', ''),
                'total': processed_fields.get('total', ''),
                'invoice_number': processed_fields.get('invoice_number', ''),
                'tax_category': processed_fields.get('tax_category', 'Ê®ôÊ∫ñÁ®éÁéá'),
                'account_title': category_result['category'],
                'confidence': category_result['confidence'],
                'subtotal': processed_fields.get('subtotal', ''),
                'tax': processed_fields.get('tax', ''),
                'currency': 'JPY',
                'payment': processed_fields.get('payment', ''),
                'change': processed_fields.get('change', ''),
                'field_confidence': confidence_scores,
                'raw_text': raw_text,
                'normalized_text': normalized_text,
                'processing_method': 'enhanced_japanese',
                'ocr_engine': ocr_result.get('metadata', {}).get('engine', 'unknown')
            }

            # Save to validation dataset
            self._save_to_validation_dataset(result, filename)

            print(f"‚úÖ Enhanced Japanese extraction complete: {result['vendor']} - ¬•{result['total']} ({result['account_title']})")
            return result

        except Exception as e:
            print(f"‚ùå Enhanced Japanese extraction failed: {e}")
            # Fallback to basic extractor if available
            if FIELD_EXTRACTOR_AVAILABLE:
                try:
                    fallback_extractor = FieldExtractor()
                    return fallback_extractor.extract_fields(None, filename)  # Will use OCR.space fallback
                except Exception as fallback_error:
                    print(f"‚ùå Fallback extraction also failed: {fallback_error}")

            return self._get_error_result(str(e), filename)

    def _normalize_japanese_text(self, text: str) -> str:
        """
        Normalize Japanese text: full-width to half-width, clean currency symbols.

        Args:
            text: Raw OCR text

        Returns:
            Normalized text
        """
        if not text:
            return ""

        # Normalize full-width characters to half-width
        normalized = unicodedata.normalize('NFKC', text)

        # Clean up common OCR artifacts
        normalized = re.sub(r'[¬•\\ÂÜÜ]', '¬•', normalized)  # Standardize currency symbols
        normalized = re.sub(r'\s+', ' ', normalized)      # Normalize whitespace
        normalized = normalized.strip()

        return normalized

    def _extract_fields_by_position(self, text_blocks: List[Dict], normalized_text: str) -> Dict[str, Any]:
        """
        Extract fields using position-aware processing based on text block locations.

        Args:
            text_blocks: Structured text blocks from DOCUMENT_TEXT_DETECTION
            normalized_text: Normalized full text

        Returns:
            Extracted field values
        """
        fields = {}

        # Classify blocks by position
        header_blocks = [b for b in text_blocks if b.get('block_type') == 'header']
        body_blocks = [b for b in text_blocks if b.get('block_type') == 'body']
        footer_blocks = [b for b in text_blocks if b.get('block_type') == 'footer']

        # Extract vendor from header (top area)
        fields['vendor'] = self._extract_vendor_from_blocks(header_blocks)

        # Extract date from header
        fields['date'] = self._extract_date_from_blocks(header_blocks + body_blocks[:2])  # First few body blocks too

        # Extract invoice number from anywhere (often in header or footer)
        fields['invoice_number'] = self._extract_invoice_from_blocks(text_blocks)

        # Extract amounts from footer (bottom area - totals, tax, payment)
        amount_fields = self._extract_amounts_from_blocks(footer_blocks)
        fields.update(amount_fields)

        # Fallback to regex extraction on full text if needed
        if not fields.get('date'):
            fields['date'] = self._extract_date_regex(normalized_text)
        if not fields.get('total'):
            fields['total'] = self._extract_total_regex(normalized_text)
        if not fields.get('tax'):
            fields['tax'] = self._extract_tax_regex(normalized_text)

        return fields

    def _extract_vendor_from_blocks(self, header_blocks: List[Dict]) -> str:
        """Extract vendor name from header blocks."""
        for block in header_blocks:
            text = block.get('text', '')
            # Look for substantial text that's likely a store name
            if len(text) >= 2 and not any(skip in text for skip in ['„É¨„Ç∑„Éº„Éà', 'È†òÂèéÊõ∏', 'RECEIPT', 'Êó•‰ªò', 'ÊôÇÈñì', 'TEL', '„Äí']):
                # Check if it matches known vendors
                for vendor_name in self.vendor_database.keys():
                    if vendor_name in text:
                        return vendor_name

                # Return first substantial text as vendor
                return text.strip()

        return ""

    def _extract_date_from_blocks(self, blocks: List[Dict]) -> str:
        """Extract date from specified blocks."""
        for block in blocks:
            text = block.get('text', '')
            date = self._extract_date_regex(text)
            if date:
                return date
        return ""

    def _extract_invoice_from_blocks(self, text_blocks: List[Dict]) -> str:
        """Extract invoice number from any block."""
        for block in text_blocks:
            text = block.get('text', '')
            for pattern in self.field_patterns['invoice_number']:
                match = re.search(pattern, text, re.IGNORECASE)
                if match:
                    candidate = match.group(1)
                    if self._is_valid_invoice_number(candidate):
                        return candidate
        return ""

    def _extract_amounts_from_blocks(self, footer_blocks: List[Dict]) -> Dict[str, str]:
        """Extract monetary amounts from footer blocks."""
        amounts = {}

        # Combine all footer text for comprehensive extraction
        footer_text = ' '.join([block.get('text', '') for block in footer_blocks])

        # Extract each amount type
        amounts['total'] = self._extract_total_regex(footer_text)
        amounts['tax'] = self._extract_tax_regex(footer_text)
        amounts['subtotal'] = self._extract_subtotal_regex(footer_text)
        amounts['payment'] = self._extract_payment_regex(footer_text)
        amounts['change'] = self._extract_change_regex(footer_text)

        return amounts

    def _extract_date_regex(self, text: str) -> str:
        """Extract date using regex patterns."""
        for pattern in self.field_patterns['date']:
            match = re.search(pattern, text)
            if match:
                try:
                    if 'Âπ¥' in text:  # Japanese format
                        year = int(match.group(1))
                        month = int(match.group(2))
                        day = int(match.group(3))
                    elif len(match.group(1)) == 4:  # YYYY format
                        year = int(match.group(1))
                        month = int(match.group(2))
                        day = int(match.group(3))
                    elif len(match.group(1)) == 2:  # YY format
                        year = 2000 + int(match.group(1))
                        month = int(match.group(2))
                        day = int(match.group(3))
                    else:  # DD/MM/YYYY or similar
                        if pattern == r'(\d{1,2})[/-](\d{1,2})[/-](\d{4})':
                            month = int(match.group(1))
                            day = int(match.group(2))
                            year = int(match.group(3))
                        else:
                            day = int(match.group(1))
                            month = int(match.group(2))
                            year = int(match.group(3))

                    # Validate date
                    if 2020 <= year <= 2030 and 1 <= month <= 12 and 1 <= day <= 31:
                        return f"{year}-{month:02d}-{day:02d}"
                except (ValueError, IndexError):
                    continue
        return ""

    def _extract_total_regex(self, text: str) -> str:
        """Extract total amount using regex."""
        for pattern in self.field_patterns['total']:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                amount = self._normalize_amount(match.group(1))
                if amount and 1 <= float(amount) <= 1000000:
                    return amount
        return ""

    def _extract_tax_regex(self, text: str) -> str:
        """Extract tax amount using regex."""
        for pattern in self.field_patterns['tax']:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                amount = self._normalize_amount(match.group(1))
                if amount and 0 <= float(amount) <= 50000:  # Tax can be 0
                    return amount
        return ""

    def _extract_subtotal_regex(self, text: str) -> str:
        """Extract subtotal amount using regex."""
        for pattern in self.field_patterns['subtotal']:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                amount = self._normalize_amount(match.group(1))
                if amount and 1 <= float(amount) <= 1000000:
                    return amount
        return ""

    def _extract_payment_regex(self, text: str) -> str:
        """Extract payment amount using regex."""
        for pattern in self.field_patterns['payment']:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                amount = self._normalize_amount(match.group(1))
                if amount and 1 <= float(amount) <= 1000000:
                    return amount
        return ""

    def _extract_change_regex(self, text: str) -> str:
        """Extract change amount using regex."""
        for pattern in self.field_patterns['change']:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                amount = self._normalize_amount(match.group(1))
                if amount and 0 <= float(amount) <= 100000:  # Change can be 0
                    return amount
        return ""

    def _normalize_amount(self, amount_str: str) -> str:
        """Normalize amount string: remove commas, ensure valid number."""
        if not amount_str:
            return ""

        # Remove commas and currency symbols
        cleaned = re.sub(r'[¬•\\,ÂÜÜ]', '', amount_str.strip())

        try:
            # Convert to float then back to int string (removes decimals if .00)
            value = float(cleaned)
            return str(int(value))
        except ValueError:
            return ""

    def _is_valid_invoice_number(self, candidate: str) -> bool:
        """Validate invoice number candidate."""
        if not candidate or len(candidate) < 2:
            return False

        # Must contain at least one digit
        if not any(c.isdigit() for c in candidate):
            return False

        # Length constraints
        if len(candidate) > 15:
            return False

        # Avoid obvious non-invoice patterns
        if any(char in candidate for char in ['%', ':', '/', '@']):
            return False

        return True

    def _apply_post_processing_logic(self, fields: Dict[str, Any]) -> Dict[str, Any]:
        """
        Apply post-processing logic to resolve conflicts and validate relationships.

        Args:
            fields: Raw extracted fields

        Returns:
            Processed fields with logic applied
        """
        processed = fields.copy()

        # Logic 1: If both Â∞èË®à and ÂêàË®à exist, prefer ÂêàË®à as total
        subtotal = processed.get('subtotal', '')
        total = processed.get('total', '')

        if subtotal and total:
            try:
                subtotal_val = float(subtotal)
                total_val = float(total)

                # If subtotal + tax would equal total, keep both
                tax = processed.get('tax', '')
                if tax:
                    tax_val = float(tax)
                    if abs((subtotal_val + tax_val) - total_val) < 2:  # Within ¬•2 tolerance
                        pass  # Keep all values
                    else:
                        # Check if total might be the correct one
                        pass
            except ValueError:
                pass

        # Logic 2: Handle Á®éËæº amounts (tax-inclusive totals)
        # If we find Á®éËæº in the text and have a total, it might be tax-inclusive

        # Logic 3: Validate payment vs total + change relationship
        payment = processed.get('payment', '')
        change_amt = processed.get('change', '')

        if payment and total and change_amt:
            try:
                payment_val = float(payment)
                total_val = float(total)
                change_val = float(change_amt)

                # Payment should equal total + change (within tolerance)
                expected_payment = total_val + change_val
                if abs(payment_val - expected_payment) > 5:  # More than ¬•5 difference
                    print(f"‚ö†Ô∏è Payment validation failed: {payment_val} != {total_val} + {change_val} = {expected_payment}")
            except ValueError:
                pass

        return processed

    def _categorize_expense_enhanced(self, fields: Dict[str, Any], text: str) -> Dict[str, float]:
        """
        Enhanced expense categorization using vendor database and fuzzy matching.

        Args:
            fields: Extracted fields including vendor
            text: Full normalized text

        Returns:
            Dict with category and confidence score
        """
        vendor = fields.get('vendor', '')

        # First, try exact match in vendor database
        if vendor in self.vendor_database:
            return {
                'category': self.vendor_database[vendor],
                'confidence': 0.95
            }

        # Try fuzzy matching for vendor name
        best_match = None
        best_score = 0

        for db_vendor, category in self.vendor_database.items():
            # Fuzzy match with multiple algorithms
            ratio_score = fuzz.ratio(vendor.lower(), db_vendor.lower())
            token_score = fuzz.token_sort_ratio(vendor.lower(), db_vendor.lower())

            # Use the better score
            score = max(ratio_score, token_score)

            if score > best_score and score > 70:  # Minimum threshold
                best_match = category
                best_score = score

        if best_match:
            confidence = min(0.9, best_score / 100)  # Cap at 90%
            return {
                'category': best_match,
                'confidence': confidence
            }

        # Fallback to keyword-based categorization
        return self._categorize_by_keywords(text)

    def _categorize_by_keywords(self, text: str) -> Dict[str, float]:
        """Fallback categorization using keyword matching."""
        text_lower = text.lower()

        # Define keyword categories (similar to original field_extractors.py)
        categories = {
            'È£üË≤ª': ['„É¨„Çπ„Éà„É©„É≥', '„É©„Éº„É°„É≥', 'ÂØøÂè∏', 'ÂÆöÈ£ü', 'È£üÂ†Ç', '„Ç´„Éï„Çß', '„Éê„Éº', 'Â±ÖÈÖíÂ±ã',
                   'ÁÑºËÇâ', '„Åô„Åó', 'Â§©„Å∑„Çâ', '„É©„Éº„É°„É≥', '„ÅÜ„Å©„Çì', '„Åù„Å∞', '‰∏º', 'ÂÆöÈ£ü', '„Éï„Ç°„Éü„É¨„Çπ',
                   '„Éï„Ç°„Çπ„Éà„Éï„Éº„Éâ', '„Éû„ÇØ„Éâ„Éä„É´„Éâ', '„Ç±„É≥„Çø„ÉÉ„Ç≠„Éº', '„Éî„Ç∂', '„Éè„É≥„Éê„Éº„Ç¨„Éº', '„Ç≥„Éº„Éí„Éº',
                   '„Ç∏„É•„Éº„Çπ', '„ÇΩ„Éï„Éà„Éâ„É™„É≥„ÇØ', '„Ç≥„É≥„Éì„Éã', '„Çπ„Éº„Éë„Éº', '„Éá„É™', 'ÊÉ£Ëèú', 'ÂºÅÂΩì',
                   '„Åä„Å´„Åé„Çä', '„Çµ„É≥„Éâ„Ç§„ÉÉ„ÉÅ', '„Éë„É≥', '„Ç±„Éº„Ç≠', '„Éá„Ç∂„Éº„Éà'],
            '‰∫§ÈÄöË≤ª': ['„Çø„ÇØ„Ç∑„Éº', '„Éê„Çπ', 'ÈõªËªä', 'Âú∞‰∏ãÈâÑ', 'Êñ∞ÂππÁ∑ö', 'È£õË°åÊ©ü', 'Á©∫Ê∏Ø', 'ÈßÖ',
                     '„Çø„Éº„Éü„Éä„É´', '‰∫§ÈÄö', '‰πóËªäÂà∏', 'ÂàáÁ¨¶', 'ÂÆöÊúüÂà∏', 'È´òÈÄüÈÅìË∑Ø', 'È´òÈÄü',
                     'ÊúâÊñôÈÅìË∑Ø', 'ÈßêËªäÂ†¥', '„Éë„Éº„Ç≠„É≥„Ç∞', '„Ç¨„ÇΩ„É™„É≥', '„Çπ„Çø„É≥„Éâ', '„É¨„É≥„Çø„Ç´„Éº'],
            'Ê∂àËÄóÂìÅË≤ª': ['ÊñáÊàøÂÖ∑', '„Éö„É≥', '„Éé„Éº„Éà', '„Éï„Ç°„Ç§„É´', '„ÇØ„É™„ÉÉ„Éó', '„Éõ„ÉÉ„ÉÅ„Ç≠„Çπ', '„ÉÜ„Éº„Éó',
                       '„Ç§„É≥„ÇØ', '„Éà„Éä„Éº', '„Ç≥„Éî„ÉºÁî®Á¥ô', 'Â∞ÅÁ≠í', 'ÂàáÊâã', '„ÅØ„Åå„Åç', '„ÉÜ„Ç£„ÉÉ„Ç∑„É•',
                       '„Éà„Ç§„É¨„ÉÉ„Éà„Éö„Éº„Éë„Éº', 'Ê¥óÂâ§', 'Áü≥Èπ∏', '„Ç∑„É£„É≥„Éó„Éº', 'Ê≠ØÁ£®„Åç', 'ÂåñÁ≤ßÂìÅ',
                       'Êó•Áî®ÂìÅ', '„Çπ„Éº„Éë„Éº', '„Ç≥„É≥„Éì„Éã', '„Éâ„É©„ÉÉ„Ç∞„Çπ„Éà„Ç¢', 'Ëñ¨Â±Ä']
        }

        scores = {}
        for category, keywords in categories.items():
            score = sum(5 for keyword in keywords if keyword in text_lower)
            if score > 0:
                scores[category] = score

        if scores:
            best_category = max(scores, key=scores.get)
            max_score = scores[best_category]
            confidence = min(0.85, max_score / 50)  # Normalize to 0-85%
            return {
                'category': best_category,
                'confidence': confidence
            }

        return {
            'category': '„Åù„ÅÆ‰ªñ',
            'confidence': 0.0
        }

    def _calculate_field_confidence(self, fields: Dict[str, Any]) -> Dict[str, float]:
        """Calculate confidence scores for each extracted field."""
        confidence = {}

        # Date confidence
        date = fields.get('date', '')
        if date:
            confidence['date'] = 0.95  # High confidence if extracted
        else:
            confidence['date'] = 0.0

        # Vendor confidence
        vendor = fields.get('vendor', '')
        if vendor:
            confidence['vendor'] = 0.90  # High confidence if extracted
        else:
            confidence['vendor'] = 0.0

        # Amount confidences (based on reasonableness)
        for field_name in ['total', 'tax', 'subtotal', 'payment', 'change']:
            amount = fields.get(field_name, '')
            if amount:
                try:
                    value = float(amount)
                    # Basic reasonableness checks
                    if field_name == 'total' and 10 <= value <= 100000:
                        confidence[field_name] = 0.95
                    elif field_name == 'tax' and 0 <= value <= 5000:
                        confidence[field_name] = 0.90
                    elif field_name in ['subtotal', 'payment'] and 10 <= value <= 100000:
                        confidence[field_name] = 0.90
                    elif field_name == 'change' and 0 <= value <= 10000:
                        confidence[field_name] = 0.85
                    else:
                        confidence[field_name] = 0.60  # Reasonable but borderline
                except ValueError:
                    confidence[field_name] = 0.0
            else:
                confidence[field_name] = 0.0

        # Invoice number confidence
        invoice = fields.get('invoice_number', '')
        if invoice:
            confidence['invoice_number'] = 0.85
        else:
            confidence['invoice_number'] = 0.0

        return confidence

    def _save_to_validation_dataset(self, result: Dict[str, Any], filename: str):
        """Save extraction result to validation dataset for continuous improvement."""
        try:
            # Create artifacts/ocr_results directory if it doesn't exist
            results_dir = os.path.join(os.path.dirname(__file__), '..', '..', 'artifacts', 'ocr_results')
            os.makedirs(results_dir, exist_ok=True)

            # Generate filename with timestamp
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            base_filename = os.path.splitext(filename)[0]
            json_filename = f"{base_filename}_{timestamp}.json"
            text_filename = f"{base_filename}_{timestamp}.txt"

            # Save structured result as JSON
            json_path = os.path.join(results_dir, json_filename)
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)

            # Save raw text for reference
            text_path = os.path.join(results_dir, text_filename)
            with open(text_path, 'w', encoding='utf-8') as f:
                f.write(result.get('raw_text', ''))

            print(f"üíæ Validation data saved: {json_filename}")

        except Exception as e:
            print(f"‚ö†Ô∏è Failed to save validation data: {e}")

    def _get_error_result(self, error_msg: str, filename: str) -> Dict[str, Any]:
        """Return error result structure."""
        return {
            'date': '',
            'vendor': '',
            'total': '',
            'invoice_number': '',
            'tax_category': '',
            'account_title': '',
            'confidence': 0.0,
            'subtotal': '',
            'tax': '',
            'currency': 'JPY',
            'error': error_msg,
            'processing_method': 'enhanced_japanese',
            'filename': filename
        }


# Convenience function for easy integration
def create_enhanced_japanese_extractor() -> EnhancedJapaneseExtractor:
    """Create and return an enhanced Japanese extractor instance."""
    return EnhancedJapaneseExtractor()